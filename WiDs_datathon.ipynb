{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <H1> Introduction </H1>\n",
    "<p>\n",
    "    This notebook contains the steps I took to analyze and label the WiDS 2018 Datathon data. The data contained demographic and behavioral information from a representative sample of survey respondents from India and their usage of traditional financial and mobile financial services. The dataset is a product of InterMedia’s research to help the world’s poorest people take advantage of widely available mobile phones and other digital technology to access financial tools and participate more fully in their local economies. \n",
    "    To obtain the data contact Intermedia directly at http://finclusion@intermedia.org and fill out a data request form [here](http://finclusion.org/data_fiinder/)\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "\n",
    "The goal of this datathon was to determine if a survey respondent was male or female (0 or 1), based on how they answered questions.\n",
    "\n",
    "I performed the following steps to produce a model with a resulting accuracy of 0.97107.\n",
    "\n",
    "   <li>Wrangling the data</li>\n",
    "   <li>Feature selection</li>\n",
    "   <li>Optimization of an XGBoost model</li>\n",
    "   <li>Use optimized model to predict labels of test dataset</li>\n",
    "    \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aregel\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# general imports\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#imports for chi-squared\n",
    "from scipy.stats import chi2_contingency\n",
    "from collections import defaultdict\n",
    "\n",
    "# imports for xgboost\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import cv\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <H1> Data Wrangle </H1>\n",
    "<p>\n",
    "    In order to build an effective model the data needs to be cleaned and orgainized. \n",
    "    \n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    <li>Read data into memory as a pandas dataframe</li>\n",
    "    <li>Remove empty columns</li>\n",
    "    <li>Ensure feature agreement between test and training data</li>\n",
    "    <li>Separate the different data types and cast the categorical data as object type</li>\n",
    "    \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training data\n",
    "df_train = pd.read_csv(r'train.csv', low_memory=False)\n",
    "df_test = pd.read_csv(r'test.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The helper function common_columns ensures feature agreement between 2 data frames, and the sufficiently_filled function removes columns that are not filled to the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def common_columns(df1, df2):\n",
    "    \"\"\"Returns tuple (df1, df2) with columns that BOTH df1 and df2 have in common\"\"\"\n",
    "    joint_column_list = list(set(df1.columns) & set(df2.columns))\n",
    "    \n",
    "    return (df1[joint_column_list], df2[joint_column_list])\n",
    "\n",
    "def sufficiently_filled(df, threshold):\n",
    "    \"\"\"\n",
    "    Removes columns from df that are below the threshold for being filled\n",
    "\n",
    "    Paramerters\n",
    "    -----------\n",
    "    df : pandas dataframe\n",
    "        dataframe with NaN values\n",
    "    threshold : int\n",
    "        number of exceptable NaN values for each column\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        dataframe with columns that have less than the threshold number of NaN values\n",
    "    \"\"\"\n",
    "    # remove all columns with no data\n",
    "    df1 = df.dropna(axis=1, how='all')\n",
    "    # counts the number of NaNs in each column and keeps only the ones with less NaNs then threshold\n",
    "    good_cols = df1.isna().astype('int').sum() < threshold\n",
    "    cols_to_keep = (good_cols[good_cols == True]).index\n",
    "    return df[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe where each column has at least 50% of entries filled\n",
    "threshold = len(df_train)/2. # define threshold\n",
    "# removes empty or insufficently filled columns\n",
    "training_data = sufficiently_filled(df_train, threshold) \n",
    "test_data = sufficiently_filled(df_test, threshold)\n",
    "\n",
    "# return dataframes with columns that are only in both test and training data\n",
    "clean_train, clean_test = common_columns(training_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cleaning process removed 946 columns and 0 rows in the training data\n"
     ]
    }
   ],
   "source": [
    "num_removed_cols = len(list(df_train)) - len(list(clean_train))\n",
    "num_removed_rows = len(df_train)-len(clean_train)\n",
    "print('The cleaning process removed {} columns and {} rows in the training data'.format(num_removed_cols, num_removed_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> Separate data by type </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 columns of text training data\n"
     ]
    }
   ],
   "source": [
    "# Isolate text data\n",
    "text_train = clean_train.select_dtypes(exclude=['float64','int64'])\n",
    "text_test = clean_test.select_dtypes(exclude=['float64', 'int64'])\n",
    "print('There are {} columns of text training data'.format(len(text_train.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4> The data dictionary provided a description of all of the categorical data. So I will use those column names to separate the categorical data from the numerical, making sure to only keep the categories that remained after cleaning the data </H4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 281 columns of categorical training data\n"
     ]
    }
   ],
   "source": [
    "# Create list of catagorical feature names\n",
    "data_dictionary = pd.read_excel('WiDS data dictionary v2.xlsx')\n",
    "col_list = list(data_dictionary['Column Name'][1:].apply(lambda x: str(x)))\n",
    "# Create list of columns in cleaned training data\n",
    "clean_data_columns = clean_train.columns\n",
    "# Create list of columns both categorical and in the cleaned training data\n",
    "categorical_column_names = [name for name in clean_data_columns if name in col_list]\n",
    "# Cast catagorical data as object datatype\n",
    "categorical_train = clean_train[categorical_column_names].drop(columns='DG1').astype('object')\n",
    "categorical_test = clean_test[categorical_column_names].drop(columns='DG1').astype('object')\n",
    "print('There are {} columns of categorical training data'.format(len(categorical_train.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7 columns of numerical training data\n"
     ]
    }
   ],
   "source": [
    "# Dataframe of numerical data\n",
    "drop_columns = categorical_column_names + list(text_train)\n",
    "numerical_train = clean_train.drop(columns=drop_columns)\n",
    "numerical_test = clean_test.drop(columns=drop_columns)\n",
    "print('There are {} columns of numerical training data'.format(len(numerical_train.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <H1> Feature Selection </H1>\n",
    "\n",
    "<p>\n",
    "    <li>Remove any column that is more than 50% NaN</li>\n",
    "    <li>Use the Chi Squared metric to determine if the categorical data is dependent on gender</li>\n",
    "    <li>One-hot encode the categorical data</li>\n",
    "    <li>Ensure training and test data have the same features</li>\n",
    " \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform dataframes where NaN = 0 and value=1, and sum them\n",
    "text_count = text_train.notna().astype(int).sum()\n",
    "categorical_count = categorical_train.notna().astype(int).sum()\n",
    "numerical_count = numerical_train.notna().astype(int).sum()\n",
    "# Define threshold for 50% filled in\n",
    "threshold = 18255*0.5\n",
    "# Transform dataframes where NaN = 0 and value=1, and sum them\n",
    "text_count = text_train.notna().astype(int).sum()\n",
    "categorical_count = categorical_train.notna().astype(int).sum()\n",
    "numerical_count = numerical_train.notna().astype(int).sum()\n",
    "# Define threshold for 50% filled in\n",
    "threshold = 18255*0.5\n",
    "\n",
    "# Create list of columns that exceed the threshold for each data type\n",
    "valid_text_columns = []\n",
    "valid_categorical_columns = []\n",
    "valid_numerical_columns = []\n",
    "for text_name, text_num, categorical_name, categorical_num,numerical_name, numerical_num in zip(text_count.index, text_count,categorical_count.index,categorical_count,numerical_count.index, numerical_count):\n",
    "    if text_num > threshold:\n",
    "        valid_text_columns.append(text_name)\n",
    "    if categorical_num > threshold:\n",
    "        valid_categorical_columns.append(categorical_name)\n",
    "    if numerical_num > threshold:\n",
    "        valid_numerical_columns.append(numerical_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# print the number of valid columns for each datatype\n",
    "print(len(valid_text_columns))\n",
    "print(len(valid_categorical_columns))\n",
    "print(len(valid_numerical_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<p>\n",
    "    <H7>\n",
    "    There is no data left after filtering out columns that are more then 50% empty, I will not be using this method during the final feature selection.  Instead I will focus on using the chi-squared metric for filtering categorical data.  \n",
    "    </H7>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <H3> Categorical data feature selection </H3>\n",
    "    <p> \n",
    "    I need to determine if any of the categorical questions are answered differently based on the gender of who is filling out the survey.  To do that I will create joint contingency tables for each one of the categorical columns and then use the chi-squared test statistic to determine if the distribution of answers is dependent on gender.  If it is, then I will keep that column to train the final model. The last step is to determine if using this feature selection method actually improves the model.\n",
    "    </p>\n",
    "    \n",
    "\n",
    "<p>\n",
    "    <li>For each categorical column:\n",
    "        \n",
    "        <ol>\n",
    "            <li>Create joint distribution table</li>\n",
    "            <li>Calculate the chi-squared contingency test statistic</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>Filter columns based on the resulting p-value</li>\n",
    "    <li>Perform one-hot encoding for the gender dependent categorical data</li>\n",
    "    <li>Verify feature selection improved the model</li>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions to turn categorical columns into joint distribution tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count values for each possible category\n",
    "def cat_count(pd_series):\n",
    "    '''Returns all possible values in a pandas series'''\n",
    "    categories = list(set(pd_series))\n",
    "    cat_count = dict.fromkeys(categories, 0)\n",
    "    for cat in pd_series:\n",
    "        cat_count[cat] += 1\n",
    "    return cat_count\n",
    "\n",
    "# function to create joint dist table\n",
    "def joint_dist_table(cat_series, df):\n",
    "    '''\n",
    "    Create a joint distribution table for pandas series\n",
    "    \n",
    "    Paramerters\n",
    "    -----------\n",
    "    cat_series:\n",
    "    df:\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Joint distribution table of the catagorical distribution for each gender\n",
    "    \n",
    "    '''\n",
    "    data = df.copy()\n",
    "    # split male and female counts, and drops and Nans\n",
    "    F_series = cat_series[data.is_female == 1].dropna()\n",
    "    M_series = cat_series[data.is_female == 0].dropna()\n",
    "    # create count of each category, for each gender\n",
    "    F = cat_count(F_series)\n",
    "    M = cat_count(M_series) \n",
    "    keep = set(F) & set(M)\n",
    "    F_new = {k: F[k] for k in keep}\n",
    "    M_new = {k: M[k] for k in keep}\n",
    "    # combine counts in dataframe\n",
    "    dist_table = pd.DataFrame.from_dict(F_new, orient='index')\n",
    "    dist_table[1] = M_new.values()\n",
    "    # format to distribution table\n",
    "    final_dist_table = dist_table.rename(columns={0:'Male',1:'Female'}).transpose()\n",
    "    return final_dist_table   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the chi-squared test statistic for each categorical feature and filter by resulting p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate p-value for each categorical value\n",
    "chi_dict = defaultdict(list)\n",
    "for cat_cols in categorical_train:\n",
    "    jd_table = joint_dist_table(categorical_train[cat_cols], df_train)\n",
    "    chi_test_value, chi_p, degfree, exp_val = chi2_contingency(jd_table)\n",
    "    chi_dict[cat_cols] = [chi_test_value, chi_p, degfree, exp_val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 204 significant categorical features\n"
     ]
    }
   ],
   "source": [
    "# filter columns based on p-value\n",
    "sig_level = 0.05 # significance level\n",
    "sig_cols = []\n",
    "\n",
    "for k,v in chi_dict.items():\n",
    "    if v[1] < sig_level:\n",
    "            sig_cols.append(k)\n",
    "# print the number of significant features\n",
    "print('There are {} significant categorical features'.format(len(sig_cols)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter and one-hot encode the siginificant categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe for only the categorical data dependent on gender\n",
    "significant_categorical_train = df_train[sig_cols].astype('object') \n",
    "significant_categorical_test = df_test[sig_cols].astype('object')\n",
    "# one-hot encode\n",
    "encoded_categorical_train = pd.get_dummies(significant_categorical_train, dummy_na=True)\n",
    "encoded_categorical_test = pd.get_dummies(significant_categorical_test, dummy_na=True)\n",
    "# make sure training and test features are the same\n",
    "joint_features = list(set(encoded_categorical_test.columns) & set(encoded_categorical_train))\n",
    "encoded_categorical_train = encoded_categorical_train[joint_features]\n",
    "encoded_categorical_test = encoded_categorical_test[joint_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to verify the feature selection improved the model, I will use an unoptimized XGBoost model to see which datasets performed the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode categorical data, without feature selection\n",
    "unfiltered_categorical_train = pd.get_dummies(categorical_train, dummy_na=True)\n",
    "unfiltered_categorical_test = pd.get_dummies(categorical_test, dummy_na=True)\n",
    "joint_features = list(set(unfiltered_categorical_test.columns) & set(unfiltered_categorical_train))\n",
    "unfiltered_categorical_train = unfiltered_categorical_train[joint_features]\n",
    "unfiltered_categorical_test = unfiltered_categorical_test[joint_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.927526705012\n",
      "0.926540673788\n",
      "0.927745823062\n",
      "0.622678718159\n",
      "0.928403177212\n"
     ]
    }
   ],
   "source": [
    "# Use un-optomized xgboost model with the numerical, categorical, and a combination of the two\n",
    "combined_data = pd.concat([encoded_categorical_train, numerical_train], axis=1) \n",
    "datasets = [unfiltered_categorical_train, significant_categorical_train.fillna(value=100).astype(int), encoded_categorical_train, numerical_train, combined_data]\n",
    "# define parameters\n",
    "fixed_parameters = {\n",
    "               'max_depth':3,\n",
    "               'learning_rate':0.3,\n",
    "               'min_child_weight':3,\n",
    "               'colsample_bytree':0.8,\n",
    "               'subsample':0.8,\n",
    "               'gamma':0,\n",
    "               'max_delta_step':0,\n",
    "               'colsample_bylevel':1,\n",
    "               'scale_pos_weight':1,\n",
    "               'base_score':0.5,\n",
    "               'random_state':5,\n",
    "               'objective':'binary:logistic',\n",
    "               'silent': 1}\n",
    "\n",
    "accuracy_scores = []\n",
    "for data in datasets:\n",
    "    # define features(X), and target(y)\n",
    "    X = data\n",
    "    y = df_train.is_female\n",
    "    # instantiate model\n",
    "    xg_reg = XGBRegressor(**fixed_parameters)\n",
    "    # fit model\n",
    "    xg_reg.fit(X, y)\n",
    "    # predict y values\n",
    "    y_pred = xg_reg.predict(X)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    # score model\n",
    "    score = accuracy_score(y, predictions)\n",
    "    print(score)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also submitted the most promising models to Kaggle.com to see how the model scored for the test data. The results are the following:\n",
    "<li>train: 0.9280 (test: 0.96762) with only encoded categorical data</li>\n",
    "<li>train: 0.9296 (test: 0.96780) with encoded categorical and numerical data</li>\n",
    "<li>train: 0.9275 (test: 0.96640) with NO feature selection on categorical data</li>\n",
    "<li>train: 0.9287 (test: 0.96809) with NO feature selection on categorical data and numerical data</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<H2> Feature selection conclusions </H2>\n",
    "\n",
    "<p> The feature selection did not improve the model, although it didn't really hurt the model either. Thus, I will continue with parameter optimization using the filtered categorical data and numerical data. That will decrease the computational resources that need to be used for optimization.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <H1>XGBoost Model Optimization</H1>\n",
    "\n",
    "<p>\n",
    "        Sklearn has two automated methods for parameter tuning: RandomizedSearchCV and GridSearchCV. RandomizedSeachCV has a set number of tests to run, and randomly chooses from the given parameter ranges and performs cross-fold validation for each test.  GridSearchCV tests every possible combination of parameters using cross-fold validation.  Given the large number of parameters I would like to optimize for, I will perform the following two steps until I've achived 0.95 or above accuracy for the test set.\n",
    "    \n",
    "    <li>Use random grid search to tune hyper-parameters</li>\n",
    "    <li>Verify random search parameters improved the model, and test to see if further optimization is needed</li>\n",
    "  \n",
    " \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of fixed parameters, which will not be optimized\n",
    "fixed_parameters = {\n",
    "    'objective':'binary:logistic',\n",
    "    'max_delta_step':0,\n",
    "    'scale_pos_weight':1,\n",
    "    'base_score':0.5,\n",
    "    'random_state':5,\n",
    "    'subsample':0.8,\n",
    "    'silent': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of parameters to optimize, and the range of optimization values\n",
    "reg_param_grid = {'max_depth': range(2,10),\n",
    "                  'learning_rate': [0.05, 0.1, 0.15, 0.3],\n",
    "                  'min_child_weight':[2,3,4],\n",
    "                  'colsample_bytree':[0.6, 0.7, 0.8],\n",
    "                  'gamma':[0, 2, 5, 8],\n",
    "                  'colsample_bylevel':[0.7, 1]\n",
    "                 }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "<p> \n",
    "    In order to computational resources, I chose only 6 parameters to optimize initially. The results of said optimization will determine if more parameter need to be considered.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, error_score='raise',\n",
       "          estimator=XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=5, silent=1, subsample=0.8),\n",
       "          fit_params=None, iid=True, n_iter=200, n_jobs=1,\n",
       "          param_distributions={'max_depth': range(2, 10), 'learning_rate': [0.05, 0.1, 0.15, 0.3], 'min_child_weight': [2, 3, 4], 'colsample_bytree': [0.6, 0.7, 0.8], 'gamma': [0, 2, 5, 8], 'colsample_bylevel': [0.7, 1]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define features and labels for training data\n",
    "X = combined_data\n",
    "y = df_train.is_female\n",
    "\n",
    "# instantiate classifier\n",
    "xg_reg = XGBRegressor(**fixed_parameters)\n",
    "\n",
    "# RandomSearch\n",
    "grid_search = RandomizedSearchCV(param_distributions = reg_param_grid, estimator = xg_reg, cv=4, n_iter=200)\n",
    "grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_child_weight': 3, 'max_depth': 8, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 0.6, 'colsample_bylevel': 1}\n",
      "0.736253869383\n"
     ]
    }
   ],
   "source": [
    "# Print best parameters and results\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using the parameters optimized by random grid search to test if it improved the model from the baseline unoptimized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_fixed_parameters = {\n",
    "    'objective':'binary:logistic',\n",
    "    'max_delta_step':0,\n",
    "    'scale_pos_weight':1,\n",
    "    'base_score':0.5,\n",
    "    'random_state':5,\n",
    "    'subsample':0.8,\n",
    "    'silent': 1,\n",
    "    'min_child_weight': 3,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.1,\n",
    "    'gamma': 0,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'colsample_bylevel': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.6,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
       "       min_child_weight=3, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=5, silent=1, subsample=0.8)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate classifier\n",
    "xg_reg = XGBRegressor(**optimized_fixed_parameters)\n",
    "xg_reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958641468091\n"
     ]
    }
   ],
   "source": [
    "# predict the labels\n",
    "y_pred = xg_reg.predict(X)\n",
    "# convert probabilities to binary output\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# score model\n",
    "score = accuracy_score(y, predictions)\n",
    "# print accuracy\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "<p> \n",
    "    The optimized parameters did improve the model from the baseline, so the next step is to use the model to predict the labels for the test data. The test predictions then need to be saved to a csv file and submitted to Kaggle.com.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test features\n",
    "X_sub = pd.concat([encoded_categorical_test, numerical_test], axis=1) \n",
    "\n",
    "# Predict label of test data with optimized model\n",
    "test_predictions = xg_reg.predict(X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place predictions and their corresponding test ID in a dataframe\n",
    "submission_df = pd.DataFrame({'test_id': df_test.test_id, 'is_female': test_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the results to a csv file, so that it can be submitted to Kaggle.com\n",
    "submission_df.to_csv('sub20.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<H2> Model optimization conclusions </H2>\n",
    "\n",
    "<p> A score of 0.97107 was achived for the test data (shown below), exceeds my goal of a 0.95 score. Thus, I will not take anymore optimization steps. However, having a training score so much lower than the test score might indicate the model is underfitted. Further steps would include using more forgiving cleaning steps to increase the number of features.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Score](img/optimized_model_score.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    <H1>Conclusions</H1>\n",
    "\n",
    "<p>\n",
    "     Due to the fact I do not own this data I cannot publish which features were the most indicative of gender.  However, I will comment on the modeling process itself.\n",
    "     \n",
    "</p>\n",
    "\n",
    "<p>\n",
    "   XGBoost worked very well, with very little optimization needed. If this were not the case, I would have tried straight logistic regression or random forests. Since the goal of this analysis was to determine the underlying issues women face, I would not use neural nets, because of poor interpretability.\n",
    "</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
